{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='Homework'></a>\n",
    "# Homework\n",
    "\n",
    "Thoery (5 points):\n",
    "- Complete theory questions in Google Form\n",
    "- Take a look at all links \n",
    "- Read and analyze all theory `TODO`s. In this lecture they are highly important \n",
    "\n",
    "Practice (10-15 points):\n",
    "- First Option (Easier) - Apply [Sentence Classification/Sentence Regression](#Sentence_Classification) approach to [CommonLit - Evaluate Student Summaries](https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries)\n",
    "    - Max Base Points: 10\n",
    "    - Tune `BERT` / `DEBERTA` or other bert-like models, maybe re-write it. Tune all other hyper-params.\n",
    "    - Try different optimizers lr schedulers \n",
    "    - Implement Cross-Validation and add test houldout\n",
    "    - Make a submit to Kaggle\n",
    "- Second Option (Harder) - Apply [Token Classification](#Token_Classification) approach to Location Detection task\n",
    "    - Max Base Points: 15\n",
    "    - Introduce fixes, mentioned in `TODO`s\n",
    "    - Your model also have to handle ukrainian and russian languages. Make sure to add `../data/mantis_analytics_location_detection/ru_geo_dataset.csv` (from https://www.kaggle.com/datasets/vladimirsydor/mantis-analytics-location-detection/data). Think about\n",
    "        - New Validation\n",
    "        - New Word Embeddings\n",
    "        - Maybe separate models\n",
    "        - IMPORTANT: Take into account `doc_id`\n",
    "        - Take into account that markup is far from ideal. Maybe pre-processing may help\n",
    "    - Coming back to Lecture 3. F1 is the final production metric but it hardly depends on threshold. Maybe you can use some \"soft\" metric for model comparison ? \n",
    "    - Do we need additional post-processing ?\n",
    "    - Tune `BERT` / `DEBERTA` or other bert-like models on the whole dataset for more epochs, maybe re-write it. Tune all other hyper-params.\n",
    "    - Try different optimizers lr schedulers \n",
    "    - Implement Cross-Validation and add test houldout\n",
    "    - Make a submit to Kaggle\n",
    "    - Additional points: first private score - 25 points, second private score - 15 points, third private score - 10 points\n",
    "    - Do not hesitate to use `Discussion` and `Code` on Kaggle. All additional useful insights will be also granted with additional scores\n",
    "        - If you do not want to share with other competitors - you can share with lectors. It can be useful for Mantis usecase \n",
    "- Third Option (Hardest). Do both first and second options\n",
    "- Form will contain separate places for First and Second Options. Just put `-` for Option, which you have not choosen "
   ],
   "metadata": {
    "papermill": {
     "duration": 0.012582,
     "end_time": "2023-10-22T21:24:08.238781",
     "exception": false,
     "start_time": "2023-10-22T21:24:08.226199",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='homework_first_option'></a>\n",
    "## First Option"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011713,
     "end_time": "2023-10-22T21:24:08.262647",
     "exception": false,
     "start_time": "2023-10-22T21:24:08.250934",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01167,
     "end_time": "2023-10-22T21:24:08.309818",
     "exception": false,
     "start_time": "2023-10-22T21:24:08.298148",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "!pip install wandb\n",
    "import wandb\n",
    "\n",
    "import re\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = ''\n",
    "os.environ[\"WANDB_PROJECT\"]=\"nlp_course_deberta_finetuning\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"end\" # upload best model to wandb artifacts after training\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import (AutoTokenizer, DataCollatorWithPadding, AutoConfig,\n",
    "                          AutoModelForSequenceClassification, TrainingArguments, Trainer,\n",
    "                          AdamW, get_constant_schedule_with_warmup)\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from datasets import Dataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 16.731652,
     "end_time": "2023-10-22T21:24:25.053631",
     "exception": false,
     "start_time": "2023-10-22T21:24:08.321979",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-10-29T09:02:43.907008Z",
     "iopub.execute_input": "2023-10-29T09:02:43.907408Z",
     "iopub.status.idle": "2023-10-29T09:03:00.379302Z",
     "shell.execute_reply.started": "2023-10-29T09:02:43.907374Z",
     "shell.execute_reply": "2023-10-29T09:03:00.377801Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (5.9.5)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (4.8.0)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "     -------------------------------------- 190.6/190.6 kB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (3.19.6)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\n",
      "     -------------------------------------- 241.0/241.0 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-win_amd64.whl (11 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from wandb) (65.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yevhe\\pycharmprojects\\iasa_nlp_course\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8801 sha256=71fd12a06d1f4ec22f4787bbf262995e1015ad86cf427fb63382d4aff9600373\n",
      "  Stored in directory: c:\\users\\yevhe\\appdata\\local\\pip\\cache\\wheels\\20\\7c\\09\\4ad42725a29fce4bc21137c7f25f062b3655a4aea5b0e8d9a2\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 pathtools-0.1.2 sentry-sdk-1.32.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "n_samples_for_train = 10# 7165  # down-sample for quick demo\n",
    "#  # 7165 - full size for CommonLit challenge\n",
    "# 10 samples - 73 seconds for the full notebook run on CPU, the main thing - training part it takes 66 seconds\n",
    "# 20 samples - 2.4 minutes passed total \n",
    "# 100 samples - 564 seconds (CPU) - full , and 8min 53s - for training the model\n",
    "# 100 samples - 41.5 seconds (CPU) - full , and 16.5 s- for training the model\n",
    "# 1000 samples - GPU - 2.1 minutes passed total \n",
    "# full - 7165 samples - GPU -  12.1 minutes passed total \n",
    "# full - 7165 samples - CPU -  7h.21min = 441 minutes passed total -- extemely slow\n",
    "\n",
    "\n",
    "model_name=\"debertav3base\"\n",
    "\n",
    "class CFG:\n",
    "    model_name=model_name #\"debertav3base\"\n",
    "    model_path=os.path.join('/kaggle', 'input', model_name)\n",
    "#     initialized_params_learning_rate=1e-6\n",
    "#     non_initialized_params_learning_rate=1e-4\n",
    "    optimizer='adafactor'\n",
    "    use_fp16=True\n",
    "    learning_rate=None # 2e-5\n",
    "    weight_decay=0.03\n",
    "    hidden_dropout_prob=0 # 0.005\n",
    "    attention_probs_dropout_prob=0.007 # 0.005\n",
    "    num_train_epochs=6\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=500\n",
    "    max_length=512\n",
    "    warmup_steps=100\n",
    "    predict_mode=False\n",
    "    report_to='wandb' if not predict_mode else 'none'\n",
    "    run_name=f'{model_name}_{optimizer}_lr{learning_rate}_dropout{hidden_dropout_prob}' if report_to=='wandb' else None\n",
    "    if predict_mode:\n",
    "        pretrained_model_path = '../input/model-debertav3base-adam-lr1e-05-dropout5e-3-fold3/model-debertav3base_adam_lr1e-05_dropout5e-3_fold3'\n",
    "#         model_artifact = 'yevhen-herasimov/nlp_course_deberta_finetuning/model-debertav3base_adam_lr1e-05_dropout5e-3_fold3:latest'\n",
    "        report_to = 'none'\n",
    "        run_name = None"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-29T09:03:00.382258Z",
     "iopub.execute_input": "2023-10-29T09:03:00.383421Z",
     "iopub.status.idle": "2023-10-29T09:03:00.393911Z",
     "shell.execute_reply.started": "2023-10-29T09:03:00.383369Z",
     "shell.execute_reply": "2023-10-29T09:03:00.392507Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "seed_everything(CFG.random_seed)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:23.534286Z",
     "iopub.execute_input": "2023-10-28T18:08:23.534622Z",
     "iopub.status.idle": "2023-10-28T18:08:23.553432Z",
     "shell.execute_reply.started": "2023-10-28T18:08:23.534590Z",
     "shell.execute_reply": "2023-10-28T18:08:23.552555Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012282,
     "end_time": "2023-10-22T21:24:25.079111",
     "exception": false,
     "start_time": "2023-10-22T21:24:25.066829",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_FOLDER = os.path.join('..', 'input')\n",
    "COMMONLIT_DATA_FOLDER = os.path.join(DATA_FOLDER, 'commonlit-evaluate-student-summaries')\n",
    "COMMONLIT_TRAIN_SUMMARIES_PATH = os.path.join(COMMONLIT_DATA_FOLDER, 'summaries_train.csv')\n",
    "COMMONLIT_TRAIN_PROMPTS_PATH = os.path.join(COMMONLIT_DATA_FOLDER, 'prompts_train.csv')\n",
    "COMMONLIT_TEST_SUMMARIES_PATH = os.path.join(COMMONLIT_DATA_FOLDER, 'summaries_test.csv')\n",
    "COMMONLIT_TEST_PROMPTS_PATH = os.path.join(COMMONLIT_DATA_FOLDER, 'prompts_test.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021819,
     "end_time": "2023-10-22T21:24:25.113401",
     "exception": false,
     "start_time": "2023-10-22T21:24:25.091582",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:23.555707Z",
     "iopub.execute_input": "2023-10-28T18:08:23.556137Z",
     "iopub.status.idle": "2023-10-28T18:08:23.562876Z",
     "shell.execute_reply.started": "2023-10-28T18:08:23.556110Z",
     "shell.execute_reply": "2023-10-28T18:08:23.561879Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    \n",
    "    train_df = pd.read_csv(COMMONLIT_TRAIN_SUMMARIES_PATH)\n",
    "    train_pt_df = pd.read_csv(COMMONLIT_TRAIN_PROMPTS_PATH)\n",
    "    test_df = pd.read_csv(COMMONLIT_TEST_SUMMARIES_PATH)\n",
    "    test_pt_df = pd.read_csv(COMMONLIT_TEST_PROMPTS_PATH)\n",
    "    \n",
    "    train_df = pd.merge(train_df, train_pt_df, on='prompt_id')\n",
    "    test_df = pd.merge(test_df, test_pt_df, on='prompt_id')\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "train_df, test_df = load_data()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:23.563920Z",
     "iopub.execute_input": "2023-10-28T18:08:23.564204Z",
     "iopub.status.idle": "2023-10-28T18:08:23.702845Z",
     "shell.execute_reply.started": "2023-10-28T18:08:23.564168Z",
     "shell.execute_reply": "2023-10-28T18:08:23.702001Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# print('Train data - not downsampled shape:', train_df.shape)\n",
    "\n",
    "# train_df = train_df.groupby('prompt_id', group_keys=False).apply(lambda x: x.sample(20)) # downsampling for quick runs\n",
    "# print('Train data - AFTER downsampling shape:', train_df.shape)\n",
    "# display(train_df.head(10))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:23.703993Z",
     "iopub.execute_input": "2023-10-28T18:08:23.704299Z",
     "iopub.status.idle": "2023-10-28T18:08:23.708809Z",
     "shell.execute_reply.started": "2023-10-28T18:08:23.704274Z",
     "shell.execute_reply": "2023-10-28T18:08:23.707785Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.012728,
     "end_time": "2023-10-22T21:24:25.330910",
     "exception": false,
     "start_time": "2023-10-22T21:24:25.318182",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Plot targets:')\n",
    "sns.scatterplot(x = train_df['content'], y = train_df['wording'], hue = train_df['prompt_id'] )\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:23.710168Z",
     "iopub.execute_input": "2023-10-28T18:08:23.710479Z",
     "iopub.status.idle": "2023-10-28T18:08:24.364964Z",
     "shell.execute_reply.started": "2023-10-28T18:08:23.710436Z",
     "shell.execute_reply": "2023-10-28T18:08:24.363997Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Distribution of values in target columns')\n",
    "\n",
    "axes[0].hist(train_df['content'], bins=100)\n",
    "axes[0].set_title('Content column')\n",
    "axes[1].hist(train_df['wording'], bins=100)\n",
    "axes[1].set_title('Wording column')\n",
    "\n",
    "plt.show();"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.711672,
     "end_time": "2023-10-22T21:24:26.055061",
     "exception": false,
     "start_time": "2023-10-22T21:24:25.343389",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:24.366247Z",
     "iopub.execute_input": "2023-10-28T18:08:24.366551Z",
     "iopub.status.idle": "2023-10-28T18:08:25.087239Z",
     "shell.execute_reply.started": "2023-10-28T18:08:24.366526Z",
     "shell.execute_reply": "2023-10-28T18:08:25.086160Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Boxplots of values in target columns')\n",
    "\n",
    "axes[0].boxplot(train_df['content'])\n",
    "axes[0].set_title('Content column')\n",
    "axes[1].boxplot(train_df['wording'])\n",
    "axes[1].set_title('Wording column')\n",
    "\n",
    "plt.show();"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.423137,
     "end_time": "2023-10-22T21:24:26.492659",
     "exception": false,
     "start_time": "2023-10-22T21:24:26.069522",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:25.088726Z",
     "iopub.execute_input": "2023-10-28T18:08:25.089142Z",
     "iopub.status.idle": "2023-10-28T18:08:25.502070Z",
     "shell.execute_reply.started": "2023-10-28T18:08:25.089105Z",
     "shell.execute_reply": "2023-10-28T18:08:25.500972Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Content column\n",
    "q1 = np.percentile(train_df['content'], 25)\n",
    "q3 = np.percentile(train_df['content'], 75)\n",
    "iqr = q3 - q1\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "num_outliers_content = len(train_df['content'][train_df['content'] > upper_bound])\n",
    "\n",
    "# Wording column\n",
    "q1 = np.percentile(train_df['wording'], 25)\n",
    "q3 = np.percentile(train_df['wording'], 75)\n",
    "iqr = q3 - q1\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "num_outliers_wording = len(train_df['wording'][train_df['wording'] > upper_bound])\n",
    "\n",
    "# Print results\n",
    "print(\"Number of data points outside Q3+1.5IQR in Content column:\", num_outliers_content)\n",
    "print(\"Number of data points outside Q3+1.5IQR in Wording column:\", num_outliers_wording)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.027615,
     "end_time": "2023-10-22T21:24:26.533819",
     "exception": false,
     "start_time": "2023-10-22T21:24:26.506204",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:25.505864Z",
     "iopub.execute_input": "2023-10-28T18:08:25.506171Z",
     "iopub.status.idle": "2023-10-28T18:08:25.517946Z",
     "shell.execute_reply.started": "2023-10-28T18:08:25.506145Z",
     "shell.execute_reply": "2023-10-28T18:08:25.516773Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Number of statistical outliers is not high, but **we can test sensitive and non-sensitive to outliers loss functions**"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.013311,
     "end_time": "2023-10-22T21:24:26.560496",
     "exception": false,
     "start_time": "2023-10-22T21:24:26.547185",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Check sequence length after preprocessing and tokenization**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess(summary):\n",
    "    # remove \\n, \\r, \\t characters from text\n",
    "    summary = re.sub(r'[\\n\\r\\t]', ' ', summary)\n",
    "    # remove extra whitespaces\n",
    "    summary = re.sub(r'\\s+', ' ', summary)\n",
    "    return summary\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(CFG.model_path))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:25.519122Z",
     "iopub.execute_input": "2023-10-28T18:08:25.519445Z",
     "iopub.status.idle": "2023-10-28T18:08:26.896313Z",
     "shell.execute_reply.started": "2023-10-28T18:08:25.519419Z",
     "shell.execute_reply": "2023-10-28T18:08:26.895486Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df['clean_text'] = train_df['text'].apply(lambda summary: preprocess(summary))\n",
    "tokenized_df = tokenizer(train_df['clean_text'].to_list())[\"input_ids\"]\n",
    "\n",
    "# Figure out number of tokens in each text\n",
    "train_n_tokens = list(map(len, tokenized_df))\n",
    "\n",
    "plt.title(\"Train N Tokens Distribution\")\n",
    "plt.hist(train_n_tokens, bins=100)\n",
    "plt.show()\n",
    "\n",
    "print(f'Number of texts above {CFG.max_length} tokens: {sum(n_tokens > CFG.max_length for n_tokens in train_n_tokens)}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:26.897756Z",
     "iopub.execute_input": "2023-10-28T18:08:26.898189Z",
     "iopub.status.idle": "2023-10-28T18:08:28.596134Z",
     "shell.execute_reply.started": "2023-10-28T18:08:26.898138Z",
     "shell.execute_reply": "2023-10-28T18:08:28.595146Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013017,
     "end_time": "2023-10-22T21:24:26.586946",
     "exception": false,
     "start_time": "2023-10-22T21:24:26.573929",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Inspired by https://www.kaggle.com/code/tsunotsuno/updated-debertav3-lgbm-with-spell-autocorrect\n",
    "# Rewrote for own purposes\n",
    "class DatasetPreprocessor:\n",
    "    \"\"\"\n",
    "    Combines text preprocessing, tokenization, dataset creation into a single class\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n",
    "        \n",
    "    def preprocess(summary):\n",
    "        # remove \\n, \\r, \\t characters from text\n",
    "        summary = re.sub(r'[\\n\\r\\t]', ' ', summary)\n",
    "        # remove extra whitespaces\n",
    "        summary = re.sub(r'\\s+', ' ', summary)\n",
    "        return summary\n",
    "\n",
    "    \n",
    "    def tokenize_function(self, sample):\n",
    "        # Deberta isn't limited to 512 input length, because of relative position embeddings, \n",
    "        # but it will slow down significantly after 512 tokens\n",
    "        tokenized = self.tokenizer(\n",
    "            sample['clean_text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=CFG.max_length)\n",
    "        \n",
    "        return {**tokenized, 'labels': [sample['content'], sample['wording']]}\n",
    "      \n",
    "        \n",
    "    def tokenize_function_test(self, sample):\n",
    "        # Deberta isn't limited to 512 input length, because of relative position embeddings, \n",
    "        # but it will slow down significantly after 512 tokens\n",
    "        tokenized = self.tokenizer(\n",
    "            sample['clean_text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=CFG.max_length)\n",
    "        \n",
    "        return {**tokenized}\n",
    "        \n",
    "        \n",
    "    def run(self, dataset, train_mode):\n",
    "        dataset['clean_text'] = dataset['text'].apply(lambda summary: preprocess(summary))\n",
    "        dataset = Dataset.from_pandas(dataset)\n",
    "        if train_mode:\n",
    "            tokenized_dataset = dataset.map(self.tokenize_function)\n",
    "            tokenized_dataset = tokenized_dataset.remove_columns(['content', 'wording'])\n",
    "        else:\n",
    "            tokenized_dataset = dataset.map(self.tokenize_function_test)\n",
    "            \n",
    "        # delete common text columns\n",
    "        tokenized_dataset = tokenized_dataset.remove_columns(['text', 'clean_text'])\n",
    "            \n",
    "        return tokenized_dataset\n",
    "\n",
    "    \n",
    "preprocessor = DatasetPreprocessor(model_name=CFG.model_name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:28.597649Z",
     "iopub.execute_input": "2023-10-28T18:08:28.597966Z",
     "iopub.status.idle": "2023-10-28T18:08:29.818369Z",
     "shell.execute_reply.started": "2023-10-28T18:08:28.597939Z",
     "shell.execute_reply": "2023-10-28T18:08:29.817353Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_rmse(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(targets, predictions):\n",
    "    content_rmse = torch.sqrt(torch.mean((targets[:, 0] - predictions[:, 0]) ** 2))\n",
    "    wording_rmse = torch.sqrt(torch.mean((targets[:, 1] - predictions[:, 1]) ** 2))\n",
    "    mcrmse = torch.mean(torch.cat((content_rmse.reshape(-1), wording_rmse.reshape(-1)), dim=0))\n",
    "    return mcrmse\n",
    "\n",
    "def compute_mcrmse_numpy(eval_pred):\n",
    "    predictions, targets = eval_pred\n",
    "    content_rmse = np.sqrt(np.mean((targets[:, 0] - predictions[:, 0]) ** 2))\n",
    "    wording_rmse = np.sqrt(np.mean((targets[:, 1] - predictions[:, 1]) ** 2))\n",
    "    mcrmse = np.mean(np.concatenate((content_rmse.reshape(-1), wording_rmse.reshape(-1)), axis=0))\n",
    "    return {\"mcrmse\": mcrmse}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:29.819586Z",
     "iopub.execute_input": "2023-10-28T18:08:29.819910Z",
     "iopub.status.idle": "2023-10-28T18:08:29.828382Z",
     "shell.execute_reply.started": "2023-10-28T18:08:29.819883Z",
     "shell.execute_reply": "2023-10-28T18:08:29.827460Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class DebertaRegressorModel:\n",
    "    def __init__(self):\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            preprocessor.tokenizer\n",
    "        )\n",
    "        self.model_config = AutoConfig.from_pretrained(CFG.model_path)\n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": CFG.hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": CFG.attention_probs_dropout_prob,\n",
    "            \"num_labels\": 2,\n",
    "            \"problem_type\": \"regression\"\n",
    "        })\n",
    "\n",
    "    \n",
    "    def train(self, fold_num, train_dataset, valid_dataset):\n",
    "                \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            CFG.model_path,\n",
    "            config=self.model_config\n",
    "        )\n",
    "        \n",
    "        if CFG.optimizer == 'adam':\n",
    "#             optimizer = AdamW([\n",
    "#                 {'params': list(model.deberta.parameters()), 'lr': CFG.initialized_params_learning_rate},\n",
    "#                 {'params': list(model.pooler.parameters()), 'lr': CFG.non_initialized_params_learning_rate},\n",
    "#                 {'params': list(model.classifier.parameters()), 'lr': CFG.non_initialized_params_learning_rate}\n",
    "#             ])\n",
    "            optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)\n",
    "            lr_scheduler = get_constant_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps = CFG.warmup_steps\n",
    "            )\n",
    "        elif CFG.optimizer == 'adafactor':\n",
    "            optimizer = Adafactor(\n",
    "                model.parameters(), \n",
    "                scale_parameter=True, \n",
    "                relative_step=True, \n",
    "                warmup_init=True, \n",
    "                lr=CFG.learning_rate\n",
    "            )\n",
    "            lr_scheduler = AdafactorSchedule(optimizer)\n",
    "         \n",
    "        \n",
    "        # TrainingArguments is used for all hyperparameters and configs\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = os.path.join(CFG.model_name, f'fold_{fold_num}'), # f'fold_{fold_num}'\n",
    "            \n",
    "            # model training arguments\n",
    "            learning_rate=CFG.learning_rate,\n",
    "            per_device_train_batch_size=CFG.batch_size,\n",
    "            per_device_eval_batch_size=CFG.batch_size,\n",
    "            num_train_epochs=CFG.num_train_epochs,\n",
    "            weight_decay=CFG.weight_decay,\n",
    "            dataloader_drop_last=True,\n",
    "            dataloader_num_workers=2,\n",
    "            fp16=CFG.use_fp16, # use FP16 for training, should increase training speed, but slightly decrease model accuracy\n",
    "            \n",
    "            # model evaludation and selection\n",
    "            save_strategy='steps', # \"steps\",\n",
    "            evaluation_strategy='steps', # \"steps\",\n",
    "            eval_steps=CFG.save_steps,\n",
    "            save_steps=CFG.save_steps,\n",
    "            logging_steps=100,\n",
    "            metric_for_best_model=\"mcrmse\",\n",
    "            greater_is_better=False,\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True, # select best model\n",
    "            report_to=CFG.report_to,\n",
    "            run_name=f'{CFG.run_name}_fold{fold_num}' if CFG.run_name is not None else None\n",
    "#             compile=True # if pytorch >2.0 for faster training\n",
    "        )\n",
    "        \n",
    "        # Trainer is a high-level api to training, prediction loops\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            data_collator = self.data_collator,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=valid_dataset,\n",
    "            tokenizer = preprocessor.tokenizer,\n",
    "            compute_metrics = compute_mcrmse_numpy,\n",
    "            optimizers=(optimizer, lr_scheduler)\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        # Finish logging current run\n",
    "        wandb.finish()\n",
    "        \n",
    "    \n",
    "    def predict(self, pretrained_model_path, test_dataset):\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_path)\n",
    "        model.eval()\n",
    "        \n",
    "        # eg. \"bert/fold_0/\"\n",
    "#         model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=CFG.model_name,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 2,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        predict_trainer = Trainer(\n",
    "            model = model, \n",
    "            args = test_args,\n",
    "            tokenizer = preprocessor.tokenizer,\n",
    "            data_collator = self.data_collator\n",
    "        )\n",
    "\n",
    "        predictions = predict_trainer.predict(test_dataset)[0]\n",
    "        print(predictions)\n",
    "        return predictions[:, 0], predictions[:, 1]\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:29.830440Z",
     "iopub.execute_input": "2023-10-28T18:08:29.830839Z",
     "iopub.status.idle": "2023-10-28T18:08:29.847363Z",
     "shell.execute_reply.started": "2023-10-28T18:08:29.830756Z",
     "shell.execute_reply": "2023-10-28T18:08:29.846444Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training/Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Finetune a model \n",
    "if not CFG.predict_mode:\n",
    "    cv = GroupKFold(n_splits=4)\n",
    "    groups = train_df['prompt_id']\n",
    "    for index, (train_idx, test_idx) in enumerate(cv.split(train_df['text'], train_df[['content', 'wording']], groups=groups), start=1):\n",
    "\n",
    "        print(f'##### Starting Fold [{index}/{4}] #####')\n",
    "\n",
    "        # Split into train and validation\n",
    "        train_split, val_split = train_df[['text', 'content', 'wording']].iloc[train_idx], \\\n",
    "            train_df[['text', 'content', 'wording']].iloc[test_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = preprocessor.run(train_split, train_mode=True)\n",
    "        valid_dataset = preprocessor.run(val_split, train_mode=True)\n",
    "\n",
    "        # Create model and perform training and validation\n",
    "        model = DebertaRegressorModel()\n",
    "        model.train(index, train_dataset, valid_dataset)\n",
    "        \n",
    "# Predict test dataset and submit results\n",
    "else:\n",
    "    test_dataset = preprocessor.run(test_df, train_mode=False)\n",
    "    \n",
    "    model = DebertaRegressorModel()\n",
    "\n",
    "    test_df['content'], test_df['wording'] = model.predict(CFG.pretrained_model_path, test_dataset)\n",
    "\n",
    "    test_df[['student_id', 'content', 'wording']].to_csv('submission.csv',index=False)\n",
    "    display(pd.read_csv('submission.csv'))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-28T18:08:29.848437Z",
     "iopub.execute_input": "2023-10-28T18:08:29.848678Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wandb Results Report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "if not CFG.predict_mode:\n",
    "    %wandb yevhen-herasimov/nlp_course_deberta_finetuning/reports/Homework-5-Conclusion--Vmlldzo1ODEwMTc4"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-29T09:20:08.643210Z",
     "iopub.execute_input": "2023-10-29T09:20:08.643604Z",
     "iopub.status.idle": "2023-10-29T09:20:08.653582Z",
     "shell.execute_reply.started": "2023-10-29T09:20:08.643566Z",
     "shell.execute_reply": "2023-10-29T09:20:08.652632Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<wandb.jupyter.IFrame at 0x7a32be726bf0>",
      "text/html": "<iframe src='https://wandb.ai/yevhen-herasimov/nlp_course_deberta_finetuning/reports/Homework-5-Conclusion--Vmlldzo1ODEwMTc4?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
